{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Environment\n",
    "시스템 내 기본 python과 jupyter notebook에서 사용하는 python이 같은 지 확인하는 법\n",
    "> Cell 내 윗 주석은 설명, 아래 주석은 찬영의 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.8\n"
     ]
    }
   ],
   "source": [
    "# 앞에 느낌표를 붙이면 터미널 명령어(Command Prompt에 명령어 입력)로써 작동하는데,\n",
    "# 컴퓨터 내 기본 python이 무엇인지 찾기 위해서 살펴본다.\n",
    "!python --version\n",
    "\n",
    "# \"Python 3.6.8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codybright\\AppData\\Local\\Programs\\Python\\Python36\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# python이 여러 개가 다운로드 된 경우 여러 개가 등장한다.\n",
    "!WHERE python\n",
    "\n",
    "# \"C:\\Users\\codybright\\AppData\\Local\\Programs\\Python\\Python36\\python.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\users\\\\codybright\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jupyter notebook이 커널로써 사용하는 python\n",
    "import sys\n",
    "sys.executable\n",
    "\n",
    "# \"c:\\\\users\\\\codybright\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\python.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로그램이 실행되는 원리\n",
    "\n",
    "`(설명을 위해 하는 설명이라 정확한 개념은 아니다)`\n",
    "\n",
    "- 프로그램이 실행되는 것은 쉽게 말하면 program.exe가 실행되는 것.\n",
    "- 그래서 우리가 Command Prompt에서 python을 입력하면 python이 실행되는 것이다.\n",
    "\n",
    "<img src=\"./public/python.PNG\" align=\"left\" width=\"700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그렇다면, 컴퓨터는 이러한 .exe 파일을 어디 있는 줄 알고 똑똑하게 실행할까? \n",
    "- 프로그램을 둘러볼 위치를 정의한 것이 바로 ***환경 변수***\n",
    "- 환경 변수는 시스템 변수와 사용자 변수가 있는데, 뭐 둘다 둘러볼 위치이고,\n",
    "- 보통 python.exe의 위치가 환경 변수 내 PATH에 저장되어 있어서 실행되는 것이다.\n",
    "\n",
    "> 그렇다면, 코드로 환경 변수 리스트를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath',\n",
       " 'C:\\\\Windows\\\\system32',\n",
       " 'C:\\\\Windows',\n",
       " 'C:\\\\Windows\\\\System32\\\\Wbem',\n",
       " 'C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\',\n",
       " 'C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common',\n",
       " 'C:\\\\WINDOWS\\\\system32',\n",
       " 'C:\\\\WINDOWS',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\Wbem',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\',\n",
       " 'C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\',\n",
       " 'C:\\\\Program Files\\\\PuTTY\\\\',\n",
       " 'C:\\\\ProgramData\\\\chocolatey\\\\bin',\n",
       " 'C:\\\\Program Files\\\\Java\\\\jdk1.8.0_221\\\\bin',\n",
       " 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR',\n",
       " 'C:\\\\Program Files\\\\nodejs\\\\',\n",
       " 'C:\\\\Program Files (x86)\\\\Yarn\\\\bin\\\\',\n",
       " 'C:\\\\Program Files (x86)\\\\Intel\\\\Intel(R) Management Engine Components\\\\DAL',\n",
       " 'C:\\\\Program Files\\\\Intel\\\\Intel(R) Management Engine Components\\\\DAL',\n",
       " 'C:\\\\Program Files\\\\Java\\\\jre1.8.0_221\\\\bin',\n",
       " 'C:\\\\Apache\\\\apache-zookeeper-3.5.6-bin\\\\bin',\n",
       " 'C:\\\\Program Files\\\\MongoDB\\\\Server\\\\4.2\\\\bin',\n",
       " 'C:\\\\Apache\\\\spark-2.4.4-bin-hadoop2.7\\\\bin',\n",
       " 'C:\\\\Apache\\\\hadoop-2.7.7\\\\bin',\n",
       " 'C:\\\\Users\\\\codybright\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\Scripts\\\\',\n",
       " 'C:\\\\Users\\\\codybright\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\',\n",
       " 'C:\\\\Users\\\\codybright\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin',\n",
       " 'C:\\\\Users\\\\codybright\\\\AppData\\\\Local\\\\Android\\\\Sdk\\\\platform-tools',\n",
       " 'C:\\\\Program Files\\\\CMake\\\\bin',\n",
       " 'C:\\\\Program Files (x86)\\\\Vim\\\\vim81',\n",
       " 'C:\\\\Program Files\\\\Git\\\\bin',\n",
       " 'C:\\\\Users\\\\codybright\\\\AppData\\\\Roaming\\\\npm',\n",
       " 'C:\\\\Users\\\\codybright\\\\AppData\\\\Local\\\\Yarn\\\\bin',\n",
       " 'C:\\\\Modeltech_pe_edu_10.4a\\\\win32pe_edu',\n",
       " 'c:\\\\users\\\\codybright\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib\\\\site-packages\\\\pywin32_system32']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"].split(\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필자의 경우 python과 관련된 부분은 아래와 같고, 결론적으로 jupyter notebook에서 쓰는 그리고 시스템 기본 python이 같다.\n",
    "\n",
    "- C:\\\\Users\\\\codybright\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\Scripts\\\\\n",
    "- C:\\\\Users\\\\codybright\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\\n",
    "- c:\\\\users\\\\codybright\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib\\\\site-packages\\\\pywin32_system32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch Environment\n",
    "\n",
    "필자도 예시 코드를 바탕으로 코드를 만드는데, 모듈 import하는 부분부터 오류가 있었다.\n",
    "<img src=\"./public/error.PNG\" align=\"left\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오류를 살펴보니, torch는 있지만, torch.utils.tensorboard은 없는 것이다.\n",
    "\n",
    "> 왜냐하면, 필자는 torch v1.0.1을 쓰는데, tensorboard는 구글 검색 결과 1.3.0부터 등장하는 듯 했다.\n",
    "\n",
    "어렵게 생각할 것 없이 업데이트를 해주면 된다.\n",
    "\n",
    "***하지만, 업데이트와 더불어 설치된 모듈 정보도 확인해보자.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.5.0+cpu\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\users\\codybright\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\n",
      "Requires: future, numpy\n",
      "Required-by: torchvision\n"
     ]
    }
   ],
   "source": [
    "# pip이 온전히 설치된 사람은 결과가 등장할 것이다.\n",
    "# 필자는 순정 python, 순정 pip을 설치하였기에 터미널에서 pip이 동작한다.\n",
    "# pip도 pip.exe와 같이 실행되는 것이다.\n",
    "\n",
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codybright\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\pip.exe\n"
     ]
    }
   ],
   "source": [
    "!WHERE pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 업그레이드의 경우 보통 검색해보면,\n",
    "\n",
    "`pip install torch` or `pip install --upgrade torch torchvision`\n",
    "\n",
    "즉, pip이 설치 명령어만 줘도 알아서 업그레이드 해준다 or 업그레이드 조건을 준다인데,\n",
    "\n",
    "사실상 여러 버전이 깔리는 것을 원치 않는다면, 삭제해주고 설치하는 것이 낫다.\n",
    "\n",
    "그래서 필자는\n",
    "\n",
    "`pip uninstall torch torchvision`\n",
    "\n",
    "`pip install torch==1.5.0+cpu torchvision==0.6.0+cpu -f https://download.pytorch.org/whl/torch_stable.html`\n",
    "\n",
    "을 실행했다.\n",
    "\n",
    "그냥 `pip install torch torchvision`을 하니 오류가 났었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Identification\n",
    "\n",
    "안면 인식 관련하여 크게, Face Detection과 Face Identification으로 나뉜다. 둘은 비슷하지만 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 이 코드가 적힌 파일 위치에 facenet_pytorch이라는 폴더가 있고, 이를 모듈처럼 불러와 사용하는데,\n",
    "\n",
    "이것도 `__init__.py`라는 파일이 있어야 이렇게 모듈처럼 불러올 수 있고, 동일 폴더 내에 있어야 하는 등 여러 조건이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글이 공개한 facenet이라는 AI 모델이 있는데, tensorflow로 작성된 것을 pytorch 형태로 공개하고 있다.\n",
    "# https://github.com/timesler/facenet-pytorch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 봤었던 MNIST의 경우, 데이터가 이미지인데 excel에 숫자로 적혀 있어서 pandas로 불러와서 이를 torch로 바꿔주었으나,\n",
    "\n",
    "`featuresTrain = torch.from_numpy(features_train)`\n",
    "\n",
    "`targetsTrain = torch.from_numpy(target_train).type(torch.LongTensor)`\n",
    "\n",
    "`train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)`\n",
    "\n",
    "여기서는 이미지 파일이기 때문에 torchvision.datasets이라는 내장된 모듈을 사용해 간편하게 불러온다.\n",
    "\n",
    "그리고 한번 이미지를 align 해야 하는 과정이 필요하다.\n",
    "\n",
    "`dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define run parameters\n",
    "\n",
    "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify `data_dir` to the location of the dataset on wish to finetune on.\n",
    "\n",
    "보통 input data 위치 및 하이퍼파라미터를 설정하는 것인데, 하이퍼 파라미터란 조정하는 수치값을 의미한다.\n",
    "\n",
    "epoch의 경우 같은 데이터로 학습을 몇 번 돌릴 것인지를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/train'\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "workers = 0 if os.name == 'nt' else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfom MTCNN facial detection\n",
    "\n",
    "Iterate through the DataLoader object and obtained cropped faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 of 2"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + '_aligned')) for p, _ in dataset.samples\n",
    "]\n",
    "        \n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inception Resnet V1 module\n",
    "\n",
    "See `help(InceptionResnetV1)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='vggface2',\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define optimizer, scheduler, dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "dataset = datasets.ImageFolder(data_dir + '_aligned', transform=trans)\n",
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "----------\n",
      "Valid |     1/1    | loss:    2.3340 | fps:   17.5593 | acc:    0.2000   \n",
      "\n",
      "Epoch 1/8\n",
      "----------\n",
      "Train |     2/2    | loss:    1.7721 | fps:    5.2278 | acc:    0.3013   \n",
      "Valid |     1/1    | loss:    1.9122 | fps:   20.4415 | acc:    0.3000   \n",
      "\n",
      "Epoch 2/8\n",
      "----------\n",
      "Train |     2/2    | loss:    1.2781 | fps:    5.5974 | acc:    0.6205   \n",
      "Valid |     1/1    | loss:    8.1243 | fps:   21.2882 | acc:    0.3000   \n",
      "\n",
      "Epoch 3/8\n",
      "----------\n",
      "Train |     2/2    | loss:    0.2506 | fps:    5.4555 | acc:    0.8817   \n",
      "Valid |     1/1    | loss:   10.8942 | fps:   20.0535 | acc:    0.3000   \n",
      "\n",
      "Epoch 4/8\n",
      "----------\n",
      "Train |     2/2    | loss:    0.2154 | fps:    5.4449 | acc:    0.9129   \n",
      "Valid |     1/1    | loss:    3.4497 | fps:   20.5441 | acc:    0.3000   \n",
      "\n",
      "Epoch 5/8\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0566 | fps:    5.5083 | acc:    1.0000   \n",
      "Valid |     1/1    | loss:    4.5156 | fps:   20.3992 | acc:    0.3000   \n",
      "\n",
      "Epoch 6/8\n",
      "----------\n",
      "Train |     2/2    | loss:    0.0390 | fps:    5.4602 | acc:    0.9844   \n",
      "Valid |     1/1    | loss:    2.4378 | fps:   21.1089 | acc:    0.5000   \n",
      "\n",
      "Epoch 7/8\n",
      "----------\n",
      "Train |     2/2    | loss:    0.2997 | fps:    5.5191 | acc:    0.9286   \n",
      "Valid |     1/1    | loss:    2.0111 | fps:   18.8819 | acc:    0.4000   \n",
      "\n",
      "Epoch 8/8\n",
      "----------\n",
      "Train |     2/2    | loss:    0.1244 | fps:    5.5580 | acc:    0.9844   \n",
      "Valid |     1/1    | loss:    1.6049 | fps:   20.8663 | acc:    0.4000   \n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in data_loader:\n",
    "    X += resnet(i[0]).tolist()\n",
    "    y.append(i[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\codybright\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\codybright\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder('./data/test')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected with probability: 0.999673\n",
      "Face detected with probability: 0.999907\n",
      "Face detected with probability: 0.999785\n",
      "Face detected with probability: 0.993947\n",
      "Face detected with probability: 1.000000\n",
      "Face detected with probability: 0.999940\n",
      "Face detected with probability: 0.999914\n",
      "Face detected with probability: 0.999175\n",
      "Face detected with probability: 0.999949\n",
      "Face detected with probability: 0.999987\n",
      "Face detected with probability: 0.999748\n",
      "Face detected with probability: 0.999990\n",
      "Face detected with probability: 0.999611\n",
      "Face detected with probability: 0.999680\n",
      "Face detected with probability: 0.999252\n",
      "Face detected with probability: 0.999713\n",
      "Face detected with probability: 0.999566\n",
      "Face detected with probability: 0.999360\n",
      "Face detected with probability: 0.999735\n",
      "Face detected with probability: 0.999720\n",
      "Face detected with probability: 0.999988\n",
      "Face detected with probability: 0.999891\n",
      "Face detected with probability: 0.999953\n",
      "Face detected with probability: 0.999914\n"
     ]
    }
   ],
   "source": [
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        print('Face detected with probability: {:8f}'.format(prob))\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.20105567574501038,\n",
       "  1.0093508958816528,\n",
       "  -3.0197691917419434,\n",
       "  -1.431556224822998,\n",
       "  -0.161705881357193,\n",
       "  3.5297024250030518],\n",
       " [3.2566351890563965,\n",
       "  -0.5873974561691284,\n",
       "  -0.4491841793060303,\n",
       "  -1.4307799339294434,\n",
       "  -1.6825058460235596,\n",
       "  0.2976542115211487],\n",
       " [2.3832597732543945,\n",
       "  -1.025325059890747,\n",
       "  -0.9885967969894409,\n",
       "  -1.9037556648254395,\n",
       "  -0.26219257712364197,\n",
       "  1.3203308582305908],\n",
       " [4.101540565490723,\n",
       "  -0.9728738069534302,\n",
       "  -1.183912992477417,\n",
       "  -1.2077406644821167,\n",
       "  -1.3294203281402588,\n",
       "  0.1973738819360733],\n",
       " [0.7505789995193481,\n",
       "  -0.7633534669876099,\n",
       "  -0.36875370144844055,\n",
       "  -0.3944219946861267,\n",
       "  -0.41211333870887756,\n",
       "  0.8050347566604614],\n",
       " [-0.5350262522697449,\n",
       "  3.7386975288391113,\n",
       "  -2.714315414428711,\n",
       "  -0.41434407234191895,\n",
       "  -2.3271849155426025,\n",
       "  1.0690582990646362],\n",
       " [-0.6033623218536377,\n",
       "  1.7489089965820312,\n",
       "  1.2840951681137085,\n",
       "  0.4830886125564575,\n",
       "  -2.871847152709961,\n",
       "  -0.9642800092697144],\n",
       " [-5.4483113288879395,\n",
       "  7.672833442687988,\n",
       "  -0.22271355986595154,\n",
       "  -2.088747978210449,\n",
       "  -1.7925697565078735,\n",
       "  0.13120698928833008],\n",
       " [1.4588913917541504,\n",
       "  -2.1864898204803467,\n",
       "  5.04411506652832,\n",
       "  -2.221233367919922,\n",
       "  -1.8454043865203857,\n",
       "  -1.0660247802734375],\n",
       " [0.8752859830856323,\n",
       "  -1.0185930728912354,\n",
       "  1.2398806810379028,\n",
       "  -0.3600415587425232,\n",
       "  -1.120173454284668,\n",
       "  -0.2991183400154114],\n",
       " [-1.9870223999023438,\n",
       "  -0.4453044533729553,\n",
       "  6.040945053100586,\n",
       "  -0.4761965870857239,\n",
       "  -2.651672601699829,\n",
       "  -1.890219807624817],\n",
       " [-0.23128604888916016,\n",
       "  -2.282639265060425,\n",
       "  7.201075553894043,\n",
       "  -0.875773549079895,\n",
       "  -2.5006680488586426,\n",
       "  -2.034525156021118],\n",
       " [-0.5071048736572266,\n",
       "  0.2301306128501892,\n",
       "  1.933323860168457,\n",
       "  -0.496211975812912,\n",
       "  -1.0094586610794067,\n",
       "  -0.12866947054862976],\n",
       " [-9.678522109985352,\n",
       "  9.507678985595703,\n",
       "  4.515726089477539,\n",
       "  -4.555509567260742,\n",
       "  2.7980360984802246,\n",
       "  -3.8374576568603516],\n",
       " [1.2802624702453613,\n",
       "  -0.8987165093421936,\n",
       "  -1.6692805290222168,\n",
       "  2.066486120223999,\n",
       "  -1.1804022789001465,\n",
       "  1.0745372772216797],\n",
       " [-1.4337372779846191,\n",
       "  0.011533737182617188,\n",
       "  -0.8018377423286438,\n",
       "  4.034280776977539,\n",
       "  -1.7524495124816895,\n",
       "  0.5292587876319885],\n",
       " [5.328285217285156,\n",
       "  -1.7194037437438965,\n",
       "  -0.9588123559951782,\n",
       "  -1.5950576066970825,\n",
       "  -1.0072064399719238,\n",
       "  0.24266105890274048],\n",
       " [1.164984941482544,\n",
       "  0.7330195903778076,\n",
       "  -0.013428859412670135,\n",
       "  -1.0337655544281006,\n",
       "  -0.5919683575630188,\n",
       "  -0.49816736578941345],\n",
       " [1.9766948223114014,\n",
       "  -0.2883298695087433,\n",
       "  -0.04737008735537529,\n",
       "  -0.6890202164649963,\n",
       "  -0.8920473456382751,\n",
       "  -0.2702692151069641],\n",
       " [3.06111478805542,\n",
       "  -0.18508988618850708,\n",
       "  0.15081430971622467,\n",
       "  -2.055617570877075,\n",
       "  0.02882203459739685,\n",
       "  -0.8617645502090454],\n",
       " [3.127030849456787,\n",
       "  -0.6006582975387573,\n",
       "  -0.5296485424041748,\n",
       "  -2.1421313285827637,\n",
       "  -0.6649119853973389,\n",
       "  0.35767287015914917],\n",
       " [-2.625108242034912,\n",
       "  4.091777324676514,\n",
       "  1.9925317764282227,\n",
       "  -2.1328163146972656,\n",
       "  -1.551958680152893,\n",
       "  -0.7952099442481995],\n",
       " [4.006503582000732,\n",
       "  -1.7480864524841309,\n",
       "  0.09914804995059967,\n",
       "  -1.1991732120513916,\n",
       "  -1.2983241081237793,\n",
       "  0.33355793356895447],\n",
       " [2.767014980316162,\n",
       "  -0.9404098987579346,\n",
       "  0.1930459439754486,\n",
       "  -0.9405481815338135,\n",
       "  -1.5078811645507812,\n",
       "  0.3743256628513336]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 0 2 4 1 1 2 2 2 2 2 4 1 3 0 2 5 5 5 2 0 5]\n",
      "['IU', 'IU', 'IU', 'IU', 'eunwoo', 'eunwoo', 'eunwoo', 'eunwoo', 'gaeri', 'gaeri', 'gaeri', 'gaeri', 'jonggook', 'jonggook', 'jonggook', 'jonggook', 'soohyang', 'soohyang', 'soohyang', 'soohyang', 'younha', 'younha', 'younha', 'younha']\n",
      "{0: 'IU', 1: 'eunwoo', 2: 'gaeri', 3: 'jonggook', 4: 'soohyang', 5: 'younha'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(embeddings.tolist()))\n",
    "print(names)\n",
    "print(dataset.idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
